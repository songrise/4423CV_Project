{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import PIL.Image as Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tf\nimport cv2\nimport sklearn as sk\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:59:37.590323Z","iopub.execute_input":"2022-04-06T14:59:37.590654Z","iopub.status.idle":"2022-04-06T14:59:43.726475Z","shell.execute_reply.started":"2022-04-06T14:59:37.590565Z","shell.execute_reply":"2022-04-06T14:59:43.725542Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"BASE_DIR = \"../input/chinese-char-classification-and-location/dataset\"\nIMG_H = IMG_W = 128\nEXAMPLE_ID = 42\nRND_SEED = 42\nVAL_SIZE = 0.2\nTEST_START = 9000\nEPOCH = 60\nBATCH_SIZE = 128\nALPHA = 5e-5\nN_CHAR = 499  # max id of characters\nMODEL_PATH = \"model.h5\"\nLABEL = {'id_1': 0, 'font_1': 1, 'c_1': 2, 'r_1': 3,\n         'id_2': 4, 'font_2': 5, 'c_2': 6, 'r_2': 7}\n\n# set random seed\nnp.random.seed(RND_SEED)\ntf.random.set_seed(RND_SEED)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:59:43.728135Z","iopub.execute_input":"2022-04-06T14:59:43.728392Z","iopub.status.idle":"2022-04-06T14:59:43.735364Z","shell.execute_reply.started":"2022-04-06T14:59:43.728352Z","shell.execute_reply":"2022-04-06T14:59:43.734256Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# load image\n\n\ndef load_all(base: str):\n    \"\"\"\n    Input: base, base directory of dataset\n    Return: all_img: Ndarray, [N,H,W]\n            all_label: Ndarray, [N,8]\n    \"\"\"\n    # load all image with label\n    label_csv = np.loadtxt(base+\"/label.csv\", dtype=str,\n                           delimiter=\",\", skiprows=1)\n\n    idx = label_csv[:, 0]\n    labels = label_csv[:, 1:]\n    labels = np.array(labels, dtype=np.int32)\n    # load all image and convert to numpy array\n    images = []\n    for img_name in idx:\n        img = Image.open(BASE_DIR+\"/images/\"+img_name)\n        img = np.array(img)\n        images.append(img)\n\n    all_img = np.array(images, dtype=np.uint8)\n    all_labels = labels\n    return all_img, all_labels\n\n\nall_img, all_labels = load_all(BASE_DIR)\n\n\n# show an example\nexample_img = all_img[EXAMPLE_ID]\nplt.title(\"Task 1: Example Image\")\nplt.imshow(example_img, cmap='gray')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:59:43.736482Z","iopub.execute_input":"2022-04-06T14:59:43.736702Z","iopub.status.idle":"2022-04-06T15:00:39.070005Z","shell.execute_reply.started":"2022-04-06T14:59:43.736671Z","shell.execute_reply":"2022-04-06T15:00:39.069338Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# task 2 of the basic task, train/test/val split\n# extract test set first\n\ndef split_dataset(all_img, all_labels, val_size=0.2, random_state=42):\n    \"\"\"\n    Input: all_img: Ndarray, [N,H,W]\n            all_labels: Ndarray, [N,8]\n            test_size: float, size of val set (portion of all_img)\n            random_state: int, random seed\n    \"\"\"\n\n    test_X = all_img[TEST_START:]\n    test_Y = all_labels[TEST_START:]\n    all_img = all_img[:TEST_START]\n    all_labels = all_labels[:TEST_START]\n    # split train/val set\n    train_X, val_X, train_Y, val_Y = train_test_split(\n        all_img, all_labels, test_size=val_size, random_state=random_state)\n    return train_X, val_X, test_X, train_Y, val_Y, test_Y\n\n\ntrain_X, val_X, test_X, train_Y, val_Y, test_Y = split_dataset(\n    all_img, all_labels, VAL_SIZE, RND_SEED)\n\nprint(\"Task 2: Train/Val split\")\nprint(\"Train size:\", train_X.shape[0])\nprint(\"Val size:\", val_X.shape[0])","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:00:39.071872Z","iopub.execute_input":"2022-04-06T15:00:39.072908Z","iopub.status.idle":"2022-04-06T15:00:39.115148Z","shell.execute_reply.started":"2022-04-06T15:00:39.072866Z","shell.execute_reply":"2022-04-06T15:00:39.114415Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Task 3\ndef extract_char(imgs, labels):\n    \"\"\"\n    extract two characters from the image, and stack them along the channel axis\n    Input: Ndarray of shape (N, H, W), all images\n    Output: Ndarray of shape (N, H//2, W//2, 2), split images\n    \"\"\"\n    imgs = np.reshape(imgs, (-1, IMG_H, IMG_W, 1))\n    r_1, c_1, r_2, c_2 = labels[:, LABEL['r_1']], labels[:,\n                                                         LABEL['c_1']], labels[:, LABEL['r_2']], labels[:, LABEL['c_2']]\n    char_1 = []\n    char_2 = []\n    for i in range(imgs.shape[0]):\n        char_1.append(imgs[i, c_1[i]:c_1[i]+64, r_1[i]:r_1[i]+64])\n        char_2.append(imgs[i, c_2[i]:c_2[i]+64, r_2[i]:r_2[i]+64])\n    char_1 = np.array(char_1)\n    char_2 = np.array(char_2)\n    # normalize the image\n    char_1 = char_1/255.\n    char_2 = char_2/255.\n    # stack the two characters along the channel axis\n    imgs_split = np.concatenate((char_1, char_2), axis=3)\n    return imgs_split\n\n\ntrain_X, test_X, val_X = extract_char(\n    train_X, train_Y),extract_char(test_X,test_Y), extract_char(val_X, val_Y)\n\n\n# First, extract the labels for all dataset\n# we only need the two id for the basic task\n\n\ndef extract_char_ids(labels):\n    \"\"\"\n    Extract id from all labels\n    Input: Ndarray of shape (N, 8), all labels\n    Output: Ndarray of shape (N, 2), only id_1 and id_2\n    \"\"\"\n    id_1 = labels[:, LABEL['id_1']]\n    id_2 = labels[:, LABEL['id_2']]\n    id_1 = np.reshape(id_1, (-1, 1))\n    id_2 = np.reshape(id_2, (-1, 1))\n    label = np.concatenate((id_1, id_2), axis=1)\n    return label\n\n\ntrain_Y, val_Y, test_Y = extract_char_ids(\n    train_Y), extract_char_ids(val_Y), extract_char_ids(test_Y)\n\n\ndef one_hot_encode(labels):\n    \"\"\"\n    One hot encoding for classification\n    Input: Ndarray [N, 2]\n    Output Ndarray [N, 2, N_CHAR]\n    \"\"\"\n    n_type = N_CHAR+1\n    labels = np.reshape(labels, (-1, 2))\n    one_hot = np.zeros((labels.shape[0], labels.shape[1], n_type))\n    for i in range(labels.shape[0]):\n        for j in range(labels.shape[1]):\n            one_hot[i, j, labels[i, j]] = 1\n    return one_hot\n\n\ntrain_Y, val_Y, test_Y = one_hot_encode(\n    train_Y), one_hot_encode(val_Y), one_hot_encode(test_Y)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:00:39.116466Z","iopub.execute_input":"2022-04-06T15:00:39.116860Z","iopub.status.idle":"2022-04-06T15:00:39.763859Z","shell.execute_reply.started":"2022-04-06T15:00:39.116820Z","shell.execute_reply":"2022-04-06T15:00:39.763117Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    input_ = Input(shape=(IMG_H//2, IMG_W//2, 1))\n    x = Conv2D(32, (3, 3), padding='same', activation='relu')(input_)\n    x = MaxPooling2D((2, 2))(x)\n    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n    x = MaxPooling2D((2, 2))(x)\n    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n    x = MaxPooling2D((2, 2))(x)\n    x = Flatten()(x)\n    x = BatchNormalization()(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    pred = Dense(N_CHAR+1, activation='softmax')(x)\n    model = Model(inputs=input_, outputs=[pred])\n    model.compile(loss='categorical_crossentropy')\n    return model\n\n\n\nmodel = get_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:00:39.764998Z","iopub.execute_input":"2022-04-06T15:00:39.765232Z","iopub.status.idle":"2022-04-06T15:00:42.206389Z","shell.execute_reply.started":"2022-04-06T15:00:39.765201Z","shell.execute_reply":"2022-04-06T15:00:42.205770Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def augment_img(imgs):\n    \"\"\"\n    randomly apply the following augmentations on batch of images\n    1. translation\n    2. erosion\n    3. dilation\n    4. shear\n    5. noise\n    6. combination of all\n    Input: imgs: Ndarray of shape (N, H, W, 2), all images\n    Output: Ndarray of shape (N, H, W, 2), all images\n    \"\"\"\n    ch_1, ch_2 = imgs[..., 0].copy(), imgs[..., 1].copy()\n    # # translate the image\n    # tr_1, tr_2 = np.ones_like(ch_1), np.ones_like(ch_2)\n    # offset = np.random.randint(-10, 10, size=(2,))\n    # tr_1[:, offset[0]:] = ch_1[:, :-offset[0]]\n    # tr_2[:, offset[1]:] = ch_2[:, :-offset[1]]\n    # # erode the image\n\n    kernel = np.ones((2, 2))\n    # erode the image\n    eroded_img = []\n    for i in range(imgs.shape[0]):\n        er_1 = cv2.erode(ch_1[i], kernel, iterations=2)\n        er_2 = cv2.erode(ch_2[i], kernel, iterations=2)\n        eroded_img.append(np.concatenate(\n            (er_1[..., np.newaxis], er_2[..., np.newaxis]), axis=2))\n    eroded_img = np.array(eroded_img)\n\n    # dilate the image\n    dilated_img = []\n    for i in range(imgs.shape[0]):\n        dil_1 = cv2.dilate(ch_1[i], kernel, iterations=2)\n        dil_2 = cv2.dilate(ch_2[i], kernel, iterations=2)\n        dilated_img.append(np.concatenate(\n            (dil_1[..., np.newaxis], dil_2[..., np.newaxis]), axis=2))\n    dilated_img = np.array(dilated_img)\n\n    # shear the image\n    sheared_img = []\n    for i in range(imgs.shape[0]):\n        scale = np.random.randint(-15, 15) / 100.\n        shear_mat = np.array([[1, scale, 0], [scale, 1, 0]], dtype=np.float32)\n        shear_1 = cv2.warpAffine(ch_1[i], shear_mat, (IMG_W//2, IMG_H//2))\n        shear_2 = cv2.warpAffine(ch_2[i], shear_mat, (IMG_W//2, IMG_H//2))\n        sheared_img.append(np.concatenate(\n            (shear_1[..., np.newaxis], shear_2[..., np.newaxis]), axis=2))\n    sheared_img = np.array(sheared_img)\n    # add noise\n    # randomly generate gaussian noise\n    noise_1 = np.random.normal(0, 0.1, size=ch_1.shape)\n    noise_2 = np.random.normal(0, 0.1, size=ch_2.shape)\n    noisy_1 = ch_1 + noise_1\n    noisy_2 = ch_2 + noise_2\n    noisy_imgs = np.concatenate(\n        (noisy_1[..., np.newaxis], noisy_2[..., np.newaxis]), axis=3)\n\n    # combine shear, dialate, translate\n    combined_img = []\n    for i in range(imgs.shape[0]):\n        scale = np.random.randint(-15, 15) / 100.\n        shear_mat = np.array([[1, scale, 0], [scale, 1, 0]], dtype=np.float32)\n        shear_1 = cv2.warpAffine(ch_1[i], shear_mat, (IMG_W//2, IMG_H//2))\n        shear_2 = cv2.warpAffine(ch_2[i], shear_mat, (IMG_W//2, IMG_H//2))\n        combined_img.append(np.concatenate(\n            (shear_1[..., np.newaxis], shear_2[..., np.newaxis]), axis=2))\n    combined_img = np.array(combined_img)\n    # dilate\n    combined_img_res = []\n    for i in range(imgs.shape[0]):\n        dil_1 = cv2.dilate(combined_img[i], kernel, iterations=2)\n        dil_2 = cv2.dilate(combined_img[i], kernel, iterations=2)\n        combined_img_res.append(np.concatenate(\n            (dil_1[..., np.newaxis], dil_2[..., np.newaxis]), axis=2))\n    combined_img_res = np.array(combined_img_res)\n\n    return imgs, eroded_img, dilated_img, sheared_img, noisy_imgs, combined_img_res\n\n\ndef bachify(X, Y, batchsize, augment=True):\n    \"\"\"\n    Input: X: Ndarray of shape (N, H, W, C), all images\n           Y: Ndarray of shape (N, 2, N_CHAR), all labels\n           batchsize: int, batch size\n    Output: Ndarray of shape (batchsize, H, W, C), batch images\n            Ndarray of shape (batchsize, 2, N_CHAR), batch labels\n    \"\"\"\n    n_batch = X.shape[0]//batchsize\n    for i in range(n_batch):\n        if augment:\n            raw, ero, dil, she, nsy, com = augment_img(\n                X[i*batchsize:(i+1)*batchsize])\n        yield np.concatenate((raw, ero, dil, she, nsy, com), axis=0), np.tile(Y[i*batchsize:(i+1)*batchsize], (6, 1, 1))\n\n\ndef augment_img(imgs):\n    \"\"\"\n    randomly apply the following augmentations on batch of images\n    1. translation\n    2. erosion\n    3. dilation\n    4. shear\n    5. noise\n    6. combination of all\n    Input: imgs: Ndarray of shape (N, H, W, 2), all images\n    Output: Ndarray of shape (N, H, W, 2), all images\n    \"\"\"\n    ch_1, ch_2 = imgs[..., 0].copy(), imgs[..., 1].copy()\n    # # translate the image\n    # tr_1, tr_2 = np.ones_like(ch_1), np.ones_like(ch_2)\n    # offset = np.random.randint(-10, 10, size=(2,))\n    # tr_1[:, offset[0]:] = ch_1[:, :-offset[0]]\n    # tr_2[:, offset[1]:] = ch_2[:, :-offset[1]]\n    # # erode the image\n\n    kernel = np.ones((2, 2))\n    # erode the image\n    eroded_img = []\n    for i in range(imgs.shape[0]):\n        er_1 = cv2.erode(ch_1[i], kernel, iterations=2)\n        er_2 = cv2.erode(ch_2[i], kernel, iterations=2)\n        eroded_img.append(np.concatenate(\n            (er_1[..., np.newaxis], er_2[..., np.newaxis]), axis=2))\n    eroded_img = np.array(eroded_img)\n\n    # dilate the image\n    dilated_img = []\n    for i in range(imgs.shape[0]):\n        dil_1 = cv2.dilate(ch_1[i], kernel, iterations=2)\n        dil_2 = cv2.dilate(ch_2[i], kernel, iterations=2)\n        dilated_img.append(np.concatenate(\n            (dil_1[..., np.newaxis], dil_2[..., np.newaxis]), axis=2))\n    dilated_img = np.array(dilated_img)\n\n    # shear the image\n    sheared_img = []\n    for i in range(imgs.shape[0]):\n        scale = np.random.randint(-15, 15) / 100.\n        shear_mat = np.array([[1, scale, 0], [scale, 1, 0]], dtype=np.float32)\n        shear_1 = cv2.warpAffine(ch_1[i], shear_mat, (IMG_W//2, IMG_H//2))\n        shear_2 = cv2.warpAffine(ch_2[i], shear_mat, (IMG_W//2, IMG_H//2))\n        sheared_img.append(np.concatenate(\n            (shear_1[..., np.newaxis], shear_2[..., np.newaxis]), axis=2))\n    sheared_img = np.array(sheared_img)\n    # add noise\n    # randomly generate gaussian noise\n    noise_1 = np.random.normal(0, 0.1, size=ch_1.shape)\n    noise_2 = np.random.normal(0, 0.1, size=ch_2.shape)\n    noisy_1 = ch_1 + noise_1\n    noisy_2 = ch_2 + noise_2\n    noisy_imgs = np.concatenate(\n        (noisy_1[..., np.newaxis], noisy_2[..., np.newaxis]), axis=3)\n\n    # combine shear, dialate, translate\n    combined_img = []\n    for i in range(imgs.shape[0]):\n        scale = np.random.randint(-15, 15) / 100.\n        shear_mat = np.array([[1, scale, 0], [scale, 1, 0]], dtype=np.float32)\n        shear_1 = cv2.warpAffine(ch_1[i], shear_mat, (IMG_W//2, IMG_H//2))\n        shear_2 = cv2.warpAffine(ch_2[i], shear_mat, (IMG_W//2, IMG_H//2))\n        combined_img.append(np.concatenate(\n            (shear_1[..., np.newaxis], shear_2[..., np.newaxis]), axis=2))\n    combined_img = np.array(combined_img)\n    # dilate\n    combined_img_res = []\n    for i in range(imgs.shape[0]):\n        dil_1 = cv2.dilate(combined_img[i,:,:,0], kernel, iterations=2)\n        dil_2 = cv2.dilate(combined_img[i,:,:,1], kernel, iterations=2)\n        combined_img_res.append(np.concatenate(\n            (dil_1[..., np.newaxis], dil_2[..., np.newaxis]), axis=2))\n    combined_img_res = np.array(combined_img_res)\n\n    return imgs, eroded_img, dilated_img, sheared_img, noisy_imgs, combined_img_res\n\n\n\ndef validation(model, val_X, val_Y):\n    \"\"\"\n    Input: model: keras model\n           val_X: Ndarray of shape (N, H, W, C), all images\n           val_Y: Ndarray of shape (N, 2, N_CHAR), all labels\n    Output: Ndarray of shape (N, 2, N_CHAR), all labels\n    \"\"\"\n    pred_1, pred_2 = model(val_X[..., 0], training=False), model(\n        val_X[..., 1], training=False)\n    pred_1_type = tf.argmax(pred_1, axis=1)\n    pred_2_type = tf.argmax(pred_2, axis=1)\n\n    gt_1_type = tf.argmax(val_Y[:, 0, :], axis=1)\n    gt_2_type = tf.argmax(val_Y[:, 1, :], axis=1)\n    acc_1 = tf.reduce_mean(\n        tf.cast(tf.equal(pred_1_type, gt_1_type), tf.float32))\n    acc_2 = tf.reduce_mean(\n        tf.cast(tf.equal(pred_2_type, gt_2_type), tf.float32))\n    print('Accuracy of the first type: {}'.format(acc_1))\n    print('Accuracy of the second type: {}'.format(acc_2))\n    print(\"Overall accuracy: {}\".format((acc_1+acc_2)/2))\n\n\ndef log_val_acc():\n    global model, val_X, val_Y\n    validation(model, val_X, val_Y)\n\n\n\n\ndef train(model, train_X, train_Y, n_epochs, batch_size):\n    \"\"\"\n    Input: n_epochs: int, number of epochs\n           batch_size: int, batch size\n    \"\"\"\n    print(\"--Start training--\")\n    optimizer = tf.keras.optimizers.Adam(lr=ALPHA)\n    for i_epoch in range(n_epochs):\n        for batch_X, batch_Y in bachify(train_X, train_Y, batch_size, augment=True):\n            with tf.GradientTape() as tape:\n                pred_1, pred_2 = model(batch_X[..., 0], training=True), model(\n                    batch_X[..., 1], training=True)\n                loss_1 = tf.reduce_mean(\n                    tf.keras.losses.categorical_crossentropy(batch_Y[:, 0, :], pred_1))\n                loss_2 = tf.reduce_mean(\n                    tf.keras.losses.categorical_crossentropy(batch_Y[:, 1, :], pred_2))\n\n                loss = loss_1 + loss_2\n            grads = tape.gradient(loss, model.trainable_variables)\n            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n        if i_epoch % 10 == 0:\n            log_val_acc()\n            print(\"---------------\")\n        print('Epoch: {}, Loss: {}'.format(i_epoch, loss))\n    # save weights\n    model.save_weights(MODEL_PATH)\n    print(\"Model saved to {}\".format(MODEL_PATH))","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:00:42.207638Z","iopub.execute_input":"2022-04-06T15:00:42.208005Z","iopub.status.idle":"2022-04-06T15:00:42.259085Z","shell.execute_reply.started":"2022-04-06T15:00:42.207968Z","shell.execute_reply":"2022-04-06T15:00:42.258143Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"try:\n    model.load_weights(MODEL_PATH+\"placeholder\")\nexcept:\n    model=get_model()\n    model.summary()\n    train(model, train_X, train_Y, EPOCH, BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:00:42.260896Z","iopub.execute_input":"2022-04-06T15:00:42.261800Z","iopub.status.idle":"2022-04-06T15:11:48.417078Z","shell.execute_reply.started":"2022-04-06T15:00:42.261734Z","shell.execute_reply":"2022-04-06T15:11:48.416203Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"validation(model, val_X, val_Y)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T15:11:48.418376Z","iopub.execute_input":"2022-04-06T15:11:48.419902Z","iopub.status.idle":"2022-04-06T15:11:48.661408Z","shell.execute_reply.started":"2022-04-06T15:11:48.419860Z","shell.execute_reply":"2022-04-06T15:11:48.659963Z"},"trusted":true},"execution_count":9,"outputs":[]}]}